# -*- coding: utf-8 -*-
"""üåø BioSync - AI-Powered Biodiversity Conservation Platform .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d5OzIHN1_JnXLS4OVCj6VzPzM1qFJEUu
"""

# BioSync - AI-Powered Biodiversity Conservation Platform
# Google Colab Implementation with Gradio Interface

# Install required packages
!pip install -q gradio pillow torch torchvision opencv-python requests pyyaml tqdm matplotlib seaborn ultralytics
!pip install -q pymongo[srv] python-dotenv dnspython

import os
import io
import cv2
import uuid
import yaml
import torch
import base64
import numpy as np
import pandas as pd
import gradio as gr
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from pymongo import MongoClient, GEOSPHERE
from pymongo.server_api import ServerApi
from ultralytics import YOLO
from torchvision import transforms
import torchvision.models as models
from torchvision.models import ResNet50_Weights

# Load environment variables from .env file (if exists)
load_dotenv()

# Configuration
class Config:
    MONGODB_URI = os.getenv('MONGODB_URI', 'mongodb+srv://<username>:<password>@cluster0.mongodb.net/')
    MODEL_PATH = 'models/species_model.pt'
    TEMP_DIR = 'temp_uploads'
    DEFAULT_MODEL = 'yolov8n'  # 'yolov8n.pt' will be downloaded by ultralytics
    CLASSES = [
        'bird', 'mammal', 'reptile', 'amphibian', 'insect', 'fish',
        'plant', 'fungus', 'endangered_species'
    ]
    # Dictionary of endangered species for demonstration
    ENDANGERED_SPECIES = {
        'Philippine Eagle': {'scientific_name': 'Pithecophaga jefferyi', 'status': 'Critically Endangered'},
        'Amur Leopard': {'scientific_name': 'Panthera pardus orientalis', 'status': 'Critically Endangered'},
        'Javan Rhino': {'scientific_name': 'Rhinoceros sondaicus', 'status': 'Critically Endangered'},
        'Mountain Gorilla': {'scientific_name': 'Gorilla beringei beringei', 'status': 'Endangered'},
        'Sea Turtle': {'scientific_name': 'Cheloniidae family', 'status': 'Endangered'},
        'Giant Panda': {'scientific_name': 'Ailuropoda melanoleuca', 'status': 'Vulnerable'},
        'Blue Whale': {'scientific_name': 'Balaenoptera musculus', 'status': 'Endangered'},
        'Snow Leopard': {'scientific_name': 'Panthera uncia', 'status': 'Vulnerable'}
    }

# Create directory for temporary uploads if it doesn't exist
Path(Config.TEMP_DIR).mkdir(parents=True, exist_ok=True)

# Database Setup
class MongoDB:
    def __init__(self):
        self.client = None
        self.db = None
        try:
            # Use the MongoDB URI from Config
            self.client = MongoClient(Config.MONGODB_URI, server_api=ServerApi('1'))
            # Send a ping to confirm a successful connection
            self.client.admin.command('ping')
            print("Connected to MongoDB!")
            self.db = self.client['biosync']

            # Create collections if they don't exist
            if 'observations' not in self.db.list_collection_names():
                self.db.create_collection('observations')
                self.db['observations'].create_index([("location", GEOSPHERE)])

            if 'species' not in self.db.list_collection_names():
                self.db.create_collection('species')

            if 'users' not in self.db.list_collection_names():
                self.db.create_collection('users')

        except Exception as e:
            print(f"MongoDB connection error: {e}")
            print("Continuing without database connection...")

    def insert_observation(self, data):
        """Insert a new observation into the database"""
        if self.db:
            try:
                result = self.db.observations.insert_one(data)
                return result.inserted_id
            except Exception as e:
                print(f"Error inserting observation: {e}")
        return None

    def get_observations(self, limit=100):
        """Get recent observations"""
        if self.db:
            try:
                return list(self.db.observations.find().sort("timestamp", -1).limit(limit))
            except Exception as e:
                print(f"Error retrieving observations: {e}")
        return []

    def close(self):
        """Close the MongoDB connection"""
        if self.client:
            self.client.close()

# Initialize MongoDB
db = MongoDB()

# AI Models
class BiodiversityAI:
    def __init__(self):
        # Initialize the general object detection model (YOLOv8)
        try:
            print("Loading YOLOv8 model...")
            self.yolo_model = YOLO(Config.DEFAULT_MODEL)
            print("YOLOv8 model loaded successfully!")
        except Exception as e:
            print(f"Error loading YOLOv8 model: {e}")
            self.yolo_model = None

        # Initialize the specialized species classification model (ResNet50)
        try:
            print("Loading ResNet50 model...")
            self.species_model = models.resnet50(weights=ResNet50_Weights.DEFAULT)
            num_ftrs = self.species_model.fc.in_features
            # Modify the final layer for our classes
            self.species_model.fc = torch.nn.Linear(num_ftrs, len(Config.CLASSES))
            self.species_model.eval()
            print("ResNet50 model loaded successfully!")

            # Define image transformations
            self.transform = transforms.Compose([
                transforms.Resize(256),
                transforms.CenterCrop(224),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
        except Exception as e:
            print(f"Error loading ResNet50 model: {e}")
            self.species_model = None

    def detect_species(self, image_path):
        """Detect species in an image using YOLOv8"""
        if self.yolo_model is None:
            return None, "Model not loaded"

        try:
            # Run YOLOv8 detection
            results = self.yolo_model(image_path)

            # Process results
            detections = []
            for result in results:
                boxes = result.boxes
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].tolist()
                    confidence = box.conf[0].item()
                    class_id = int(box.cls[0].item())
                    class_name = result.names[class_id]

                    detections.append({
                        'class': class_name,
                        'confidence': confidence,
                        'bbox': [x1, y1, x2, y2]
                    })

            # Generate annotated image
            annotated_img = results[0].plot()
            annotated_img = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)

            return detections, annotated_img
        except Exception as e:
            print(f"Error in detect_species: {e}")
            return None, f"Error: {str(e)}"

    def classify_species(self, image_path):
        """Classify the species in an image using our specialized model"""
        if self.species_model is None:
            # For demonstration, we'll return a mock response
            image = cv2.imread(image_path)
            if image is None:
                return {"error": "Could not read image"}, None

            # Randomly select an endangered species for demonstration
            species_name = np.random.choice(list(Config.ENDANGERED_SPECIES.keys()))
            species_info = Config.ENDANGERED_SPECIES[species_name]

            # Create mock confidence scores
            confidences = {}
            total = 0
            for cls in Config.CLASSES:
                if cls == 'endangered_species':
                    score = np.random.uniform(0.7, 0.95)
                else:
                    score = np.random.uniform(0, 0.3)
                confidences[cls] = score
                total += score

            # Normalize confidences
            for cls in confidences:
                confidences[cls] /= total

            result = {
                "top_class": "endangered_species",
                "confidences": confidences,
                "endangered_species": species_name,
                "scientific_name": species_info['scientific_name'],
                "conservation_status": species_info['status']
            }

            # Create visualization
            img = cv2.imread(image_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

            # Add text with species information
            font = cv2.FONT_HERSHEY_SIMPLEX
            cv2.putText(img, f"Species: {species_name}", (10, 30), font, 0.7, (255, 0, 0), 2)
            cv2.putText(img, f"Scientific: {species_info['scientific_name']}", (10, 60), font, 0.7, (255, 0, 0), 2)
            cv2.putText(img, f"Status: {species_info['status']}", (10, 90), font, 0.7, (255, 0, 0), 2)

            return result, img

        # Actual implementation would go here when we have a trained model
        try:
            # Preprocess the image
            img = Image.open(image_path).convert('RGB')
            img_t = self.transform(img)
            batch_t = torch.unsqueeze(img_t, 0)

            # Get model predictions
            with torch.no_grad():
                outputs = self.species_model(batch_t)
                probabilities = torch.nn.functional.softmax(outputs, dim=1)[0]

            # Get class confidences
            confidences = {Config.CLASSES[i]: float(probabilities[i]) for i in range(len(Config.CLASSES))}
            top_class_idx = int(torch.argmax(probabilities))
            top_class = Config.CLASSES[top_class_idx]

            # Create visualization
            img_cv = cv2.imread(image_path)
            img_cv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)

            # Add text with species information
            font = cv2.FONT_HERSHEY_SIMPLEX
            cv2.putText(img_cv, f"Class: {top_class}", (10, 30), font, 0.7, (255, 0, 0), 2)
            cv2.putText(img_cv, f"Confidence: {confidences[top_class]:.2f}", (10, 60), font, 0.7, (255, 0, 0), 2)

            return {
                "top_class": top_class,
                "confidences": confidences
            }, img_cv

        except Exception as e:
            print(f"Error in classify_species: {e}")
            return {"error": str(e)}, None

# Initialize AI models
ai_engine = BiodiversityAI()

# Helper functions
def save_uploaded_file(file):
    """Save an uploaded file and return the path"""
    if file is None:
        return None

    filename = f"{uuid.uuid4()}.jpg"
    filepath = os.path.join(Config.TEMP_DIR, filename)

    # Make sure the file is in the right format
    if isinstance(file, np.ndarray):
        # Convert numpy array to image
        cv2.imwrite(filepath, cv2.cvtColor(file, cv2.COLOR_RGB2BGR))
    else:
        # Save uploaded file
        file_path = Path(file)
        img = Image.open(file_path).convert('RGB')
        img.save(filepath)

    return filepath

def create_observation_record(species_data, latitude, longitude, user_notes, image_path):
    """Create a structured observation record for the database"""
    # Convert image to base64 for storage
    with open(image_path, "rb") as img_file:
        img_base64 = base64.b64encode(img_file.read()).decode('utf-8')

    return {
        "observation_id": str(uuid.uuid4()),
        "timestamp": datetime.utcnow(),
        "species_data": species_data,
        "location": {
            "type": "Point",
            "coordinates": [float(longitude), float(latitude)]
        },
        "user_notes": user_notes,
        "image": img_base64,
        "verified": False
    }

def generate_biodiversity_report(observations):
    """Generate a biodiversity report from observations"""
    if not observations:
        return "No observations available for report generation."

    # Extract species counts
    species_counts = {}
    for obs in observations:
        if 'species_data' in obs and 'endangered_species' in obs['species_data']:
            species = obs['species_data']['endangered_species']
            species_counts[species] = species_counts.get(species, 0) + 1

    # Create a report
    report = "# BioSync Biodiversity Report\n\n"
    report += f"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
    report += f"Total Observations: {len(observations)}\n"
    report += f"Unique Species: {len(species_counts)}\n\n"
    report += "## Species Distribution\n\n"

    for species, count in sorted(species_counts.items(), key=lambda x: x[1], reverse=True):
        report += f"- {species}: {count} observations\n"

    # Create visualization
    if species_counts:
        plt.figure(figsize=(10, 6))
        sns.barplot(x=list(species_counts.keys()), y=list(species_counts.values()))
        plt.title('Species Distribution')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()

        # Save figure to a bytes buffer
        buf = io.BytesIO()
        plt.savefig(buf, format='png')
        buf.seek(0)

        # Convert to base64 for embedding in report
        img_base64 = base64.b64encode(buf.read()).decode('utf-8')
        plt.close()

        report += f"\n![Species Distribution](data:image/png;base64,{img_base64})\n"

    return report

# Gradio Interface Functions
def identify_species(image, latitude, longitude, user_notes):
    """Main function for the Gradio interface to identify species"""
    if image is None:
        return None, "Please upload an image to identify species.", None

    try:
        # Save the uploaded image
        image_path = save_uploaded_file(image)

        # Process with AI models
        detections, yolo_img = ai_engine.detect_species(image_path)
        species_data, classified_img = ai_engine.classify_species(image_path)

        # Combine the results
        if 'error' in species_data:
            result_text = f"Error: {species_data['error']}"
        else:
            # Create a more interesting result text
            if 'endangered_species' in species_data:
                species_name = species_data['endangered_species']
                scientific_name = species_data.get('scientific_name', 'Unknown')
                conservation_status = species_data.get('conservation_status', 'Unknown')

                result_text = f"""
# üåø BioSync Species Identification üåø

## üîç Species Detected
**Common Name:** {species_name}
**Scientific Name:** *{scientific_name}*
**Conservation Status:** {conservation_status}

## üìä Analysis Confidence
BioSync AI is {species_data['confidences'].get('endangered_species', 0)*100:.1f}% confident in this identification.

## üåç Location Data
**Coordinates:** {latitude}, {longitude}

## üìù Observer Notes
{user_notes if user_notes else "No notes provided."}

## üîî Conservation Alert
This species requires protection! Your observation has been logged for conservation efforts.
"""
            else:
                top_class = species_data.get('top_class', 'Unknown')
                confidence = species_data.get('confidences', {}).get(top_class, 0)

                result_text = f"""
# üåø BioSync Species Identification üåø

## üîç Classification Result
**Category:** {top_class.replace('_', ' ').title()}
**Confidence:** {confidence*100:.1f}%

## üåç Location Data
**Coordinates:** {latitude}, {longitude}

## üìù Observer Notes
{user_notes if user_notes else "No notes provided."}

Thank you for contributing to biodiversity monitoring!
"""

        # Store observation in database
        if latitude and longitude:
            try:
                obs_data = create_observation_record(
                    species_data,
                    latitude,
                    longitude,
                    user_notes,
                    image_path
                )
                db.insert_observation(obs_data)
            except Exception as e:
                print(f"Error storing observation: {e}")

        # Return the results for the Gradio interface
        return classified_img, result_text, yolo_img

    except Exception as e:
        print(f"Error in identify_species: {e}")
        return None, f"An error occurred: {str(e)}", None

def generate_report():
    """Generate a biodiversity report from all observations"""
    try:
        observations = db.get_observations(limit=100)
        report = generate_biodiversity_report(observations)
        return report
    except Exception as e:
        print(f"Error generating report: {e}")
        return f"Error generating report: {str(e)}"

# Gradio Interface Setup
def create_gradio_interface():
    """Create and launch the Gradio interface"""
    with gr.Blocks(title="BioSync - AI-Powered Biodiversity Conservation") as interface:
        gr.Markdown("# üåø BioSync - AI-Powered Biodiversity Conservation Platform üåø")
        gr.Markdown("""
        Turn every citizen into a conservationist with real-time biodiversity tracking,
        AI-driven species identification, and gamified community action.

        Upload an image to identify species and contribute to conservation efforts!
        """)

        with gr.Tabs():
            with gr.TabItem("Species Identification"):
                with gr.Row():
                    with gr.Column(scale=1):
                        input_image = gr.Image(label="Upload Image", type="filepath")
                        latitude = gr.Number(label="Latitude (optional)", value=0.0)
                        longitude = gr.Number(label="Longitude (optional)", value=0.0)
                        user_notes = gr.Textbox(label="Your Notes (optional)", placeholder="Add your observations here...")
                        submit_btn = gr.Button("Identify Species", variant="primary")

                    with gr.Column(scale=1):
                        output_image = gr.Image(label="Classified Species")
                        result_text = gr.Markdown(label="Identification Results")

                with gr.Row():
                    detection_image = gr.Image(label="Object Detection Results")

            with gr.TabItem("Biodiversity Report"):
                report_btn = gr.Button("Generate Biodiversity Report")
                report_output = gr.Markdown(label="Biodiversity Report")

        # Set up event handlers
        submit_btn.click(
            fn=identify_species,
            inputs=[input_image, latitude, longitude, user_notes],
            outputs=[output_image, result_text, detection_image]
        )

        report_btn.click(
            fn=generate_report,
            inputs=[],
            outputs=[report_output]
        )

        gr.Markdown("""
        ## About BioSync

        BioSync is an AI-powered platform that helps conserve biodiversity through:

        - üîç AI-powered species detection and identification
        - üåç Crowdsourced biodiversity monitoring
        - ‚ö†Ô∏è Real-time poaching alerts and habitat health scoring
        - üèÜ Gamified conservation incentives

        Your contributions help protect endangered species and their habitats!
        """)

    return interface

# Main execution
if __name__ == "__main__":
    # Create and launch the Gradio interface
    interface = create_gradio_interface()

    # Use share=True for public URL (temporary)
    interface.launch(share=True)

    # Clean up
    db.close()